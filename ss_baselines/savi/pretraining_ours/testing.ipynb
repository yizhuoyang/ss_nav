{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4bbb252-5a1b-4784-b62d-98a8abbb194a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
      "2025-12-31 11:14:01.819146: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-31 11:14:02.072152: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-31 11:14:03.282166: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'configs/semantic_audionav/savi/mp3d/semantic_audiogoal.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 30\u001b[0m\n\u001b[1;32m     24\u001b[0m CKPT_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/Disk/yyz/sound-spaces/data/models/savi_final_depth/ckpt.73.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m   \u001b[38;5;66;03m# or None\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# -----------------------\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# 2) 构建 config / dataset\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# -----------------------\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mget_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m meta_dir \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mTASK_CONFIG\u001b[38;5;241m.\u001b[39mSIMULATOR\u001b[38;5;241m.\u001b[39mAUDIO\u001b[38;5;241m.\u001b[39mMETADATA_DIR\n\u001b[1;32m     33\u001b[0m scenes \u001b[38;5;241m=\u001b[39m SCENE_SPLITS[SPLIT]\n",
      "File \u001b[0;32m/home/Disk/yyz/sound-spaces/ss_baselines/savi/config/default.py:260\u001b[0m, in \u001b[0;36mget_config\u001b[0;34m(config_paths, opts, model_dir, run_type, overwrite)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Create a unified config with default values overwritten by values from\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m`config_paths` and overwritten by options from `opts`.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;124;03m    run_type: either train or eval\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    259\u001b[0m config \u001b[38;5;241m=\u001b[39m merge_from_path(_C\u001b[38;5;241m.\u001b[39mclone(), config_paths)\n\u001b[0;32m--> 260\u001b[0m config\u001b[38;5;241m.\u001b[39mTASK_CONFIG \u001b[38;5;241m=\u001b[39m \u001b[43mget_task_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBASE_TASK_CONFIG_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# config_name = os.path.basename(config_paths).split('.')[0]\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/home/Disk/yyz/sound-spaces/ss_baselines/savi/config/default.py:324\u001b[0m, in \u001b[0;36mget_task_config\u001b[0;34m(config_paths, opts)\u001b[0m\n\u001b[1;32m    321\u001b[0m             config_paths \u001b[38;5;241m=\u001b[39m [config_paths]\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m config_path \u001b[38;5;129;01min\u001b[39;00m config_paths:\n\u001b[0;32m--> 324\u001b[0m         \u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opts:\n\u001b[1;32m    327\u001b[0m     config\u001b[38;5;241m.\u001b[39mmerge_from_list(opts)\n",
      "File \u001b[0;32m~/anaconda3/envs/sim/lib/python3.9/site-packages/yacs/config.py:211\u001b[0m, in \u001b[0;36mCfgNode.merge_from_file\u001b[0;34m(self, cfg_filename)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmerge_from_file\u001b[39m(\u001b[38;5;28mself\u001b[39m, cfg_filename):\n\u001b[1;32m    210\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a yaml config file and merge it this CfgNode.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    212\u001b[0m         cfg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_cfg(f)\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerge_from_other_cfg(cfg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'configs/semantic_audionav/savi/mp3d/semantic_audiogoal.yaml'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from soundspaces.utils import load_metadata\n",
    "from ss_baselines.savi.pretraining_ours.audiogoal_predictor import AudioGoalPredictor\n",
    "from ss_baselines.savi.pretraining_ours.audiogoal_dataset import AudioGoalDataset\n",
    "from ss_baselines.savi.config.default import get_config\n",
    "from soundspaces.mp3d_utils import SCENE_SPLITS\n",
    "\n",
    "# -----------------------\n",
    "# 1) 基本配置（你按需改）\n",
    "# -----------------------\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "CONFIG_PATH = \"/home/Disk/sound-space/ss_baselines/savi/config/semantic_audionav/savi.yaml\"\n",
    "SPLIT = \"val\"                 # \"train\" / \"val\" / \"test\"\n",
    "USE_CACHE = False             # 建议 inference 时 False，避免占用巨大内存\n",
    "SAMPLE_INDEX = 0              # 你要看的 dataset index\n",
    "PREDICT_LABEL = False\n",
    "PREDICT_LOCATION = True\n",
    "\n",
    "# 可选：加载 ckpt（设为 None 就不加载）\n",
    "CKPT_PATH = \"/home/Disk/yyz/sound-spaces/data/models/savi_final_depth/ckpt.73.pth\"   # or None\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 2) 构建 config / dataset\n",
    "# -----------------------\n",
    "config = get_config(config_paths=CONFIG_PATH, opts=None, run_type=None)\n",
    "meta_dir = config.TASK_CONFIG.SIMULATOR.AUDIO.METADATA_DIR\n",
    "\n",
    "scenes = SCENE_SPLITS[SPLIT]\n",
    "\n",
    "scene_graphs = {}\n",
    "for scene in scenes:\n",
    "    points, graph = load_metadata(os.path.join(meta_dir, \"mp3d\", scene))\n",
    "    scene_graphs[scene] = graph\n",
    "\n",
    "dataset = AudioGoalDataset(\n",
    "    scene_graphs=scene_graphs,\n",
    "    scenes=scenes,\n",
    "    split=SPLIT,\n",
    "    use_polar_coordinates=False,\n",
    "    use_cache=USE_CACHE,\n",
    ")\n",
    "\n",
    "print(f\"[INFO] dataset split={SPLIT}, len={len(dataset)}\")\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 3) 构建模型 + 可选加载权重\n",
    "# -----------------------\n",
    "model = AudioGoalPredictor(\n",
    "    predict_label=PREDICT_LABEL,\n",
    "    predict_location=PREDICT_LOCATION\n",
    ").to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "if CKPT_PATH is not None and os.path.exists(CKPT_PATH):\n",
    "    ckpt = torch.load(CKPT_PATH, map_location=\"cpu\")\n",
    "    # 你的 trainer 存的是 {\"audiogoal_predictor\": state_dict}\n",
    "    if \"audiogoal_predictor\" in ckpt:\n",
    "        model.load_state_dict(ckpt[\"audiogoal_predictor\"], strict=True)\n",
    "        print(f\"[INFO] loaded ckpt: {CKPT_PATH}\")\n",
    "    else:\n",
    "        # 万一你保存的是裸 state_dict\n",
    "        model.load_state_dict(ckpt, strict=True)\n",
    "        print(f\"[INFO] loaded ckpt (raw state_dict): {CKPT_PATH}\")\n",
    "else:\n",
    "    print(\"[WARN] ckpt not loaded (path is None or not exists).\")\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 4) 取一个 sample，跑一次 forward\n",
    "# -----------------------\n",
    "(inputs_list, gt) = dataset[SAMPLE_INDEX]      # inputs_list = [spectrogram], gt shape (3,)\n",
    "spectrogram = inputs_list[0]                  # torch tensor, shape (2, 65, 26)\n",
    "depth = inputs_list[1]                # torch tensor, shape (1, 128, 128)  （没用到）\n",
    "\n",
    "# 加 batch 维度 -> (1, 2, 65, 26)\n",
    "spec = spectrogram.unsqueeze(0).to(DEVICE, dtype=torch.float32)\n",
    "depth = depth.unsqueeze(0).to(DEVICE, dtype=torch.float32)  # (1,1,128,128)\n",
    "# with torch.no_grad():\n",
    "#     pred = model({\"spectrogram\": x})          # shape: (1, C) or (1, C+2) or (1,2)\n",
    "#     pred = pred.squeeze(0).cpu()\n",
    "\n",
    "# gt_np = gt.cpu().numpy() if torch.is_tensor(gt) else np.array(gt)\n",
    "\n",
    "# print(\"========== SAMPLE ==========\")\n",
    "# print(\"Index:\", SAMPLE_INDEX)\n",
    "# print(\"Spectrogram shape:\", spectrogram.shape)\n",
    "\n",
    "# print(\"\\n========== GT ==========\")\n",
    "# # gt[0] 是 label index；gt[1:] 是 (x,y)\n",
    "# print(\"GT label:\", int(gt_np[0]))\n",
    "# print(\"GT xy   :\", gt_np[1:])\n",
    "\n",
    "# print(\"\\n========== PRED ==========\")\n",
    "# if PREDICT_LABEL and PREDICT_LOCATION:\n",
    "#     # pred[:-2] logits, pred[-2:] xy\n",
    "#     logits = pred[:-2].numpy()\n",
    "#     xy = pred[-2:].numpy()\n",
    "#     pred_label = int(np.argmax(np.abs(logits)))\n",
    "#     print(\"Pred label:\", pred_label)\n",
    "#     print(\"Pred xy   :\", xy)\n",
    "# elif PREDICT_LABEL:\n",
    "#     logits = pred.numpy()\n",
    "#     pred_label = int(np.argmax(np.abs(logits)))\n",
    "#     print(\"Pred label:\", pred_label)\n",
    "# elif PREDICT_LOCATION:\n",
    "#     xy = pred.numpy()\n",
    "#     print(\"Pred xy:\", xy)\n",
    "\n",
    "# print(\"\\n[INFO] raw pred tensor shape:\", tuple(pred.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bd15427-9a9e-483b-8755-f477008a16ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [00:05<00:00, 14.54it/s]\n"
     ]
    }
   ],
   "source": [
    "import os, pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "pkl_dir = \"/home/Disk/yyz/sound-spaces/data/scene_observations/mp3d\"   # 你的 pkl 目录\n",
    "out_dir = \"/home/Disk/sound-space/depth_npy/mp3d\"            # 输出目录\n",
    "\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "for fname in tqdm([f for f in os.listdir(pkl_dir) if f.endswith(\".pkl\")]):\n",
    "    scene = os.path.splitext(fname)[0]\n",
    "    pkl_path = os.path.join(pkl_dir, fname)\n",
    "\n",
    "    with open(pkl_path, \"rb\") as f:\n",
    "        data = pickle.load(f)  # dict[(node,angle)] -> {\"rgb\",\"depth\"}\n",
    "\n",
    "    scene_out = os.path.join(out_dir, scene)\n",
    "    os.makedirs(scene_out, exist_ok=True)\n",
    "\n",
    "    for (node, ang), obs in data.items():\n",
    "        depth = obs[\"depth\"]  # (128,128,1) float32\n",
    "        # 存成 (1,H,W) 更符合 pytorch\n",
    "        if depth.ndim == 3 and depth.shape[-1] == 1:\n",
    "            depth = depth.transpose(2,0,1)  # (1,128,128)\n",
    "\n",
    "        # 可选：float16 省一半空间/IO\n",
    "        # depth = depth.astype(np.float16)\n",
    "\n",
    "        dpath = os.path.join(scene_out, f\"{node}_{ang}.npy\")\n",
    "        np.save(dpath, depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b395864",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
